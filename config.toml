# Ultra-Fast AI Model Configuration
# Version: 0.1.0

[model]
# Core model parameters
max_parameters = 100_000_000  # 100M parameter limit
model_path = "models/ultra-fast-ai.safetensors"
enable_agentic = true
enable_sparse_activations = true
sparse_activation_rate = 0.15  # 15% activation rate
quantization_bits = 4

# Performance constraints
max_inference_latency_ms = 100
max_power_consumption_w = 50.0
target_cpu_cores = 8

[training]
# Training configuration
dataset_path = "__fixtures__/datasets/"
max_training_time_hours = 24
max_vram_gb = 8.0
batch_size = 16
learning_rate = 1e-4
epochs = 20
enable_genetic_optimization = true

# Dataset configuration
datasets = [
    "humaneval",
    "tinystories", 
    "gsm8k",
    "babylm",
    "minipile"
]

[architecture]
# Hybrid neural architecture
[architecture.snn]
enabled = true
threshold = 0.5
decay_rate = 0.9
refractory_period = 2
spike_encoding = "rate"

[architecture.ssm]
enabled = true
state_size = 256
sequence_length = 2048
linear_scaling = true
mamba_style = true

[architecture.liquid_nn]
enabled = true
time_constant_min = 0.1
time_constant_max = 10.0
adaptivity_rate = 0.01
plasticity_enabled = true

[fusion]
# Output fusion configuration
fusion_method = "weighted_average"
confidence_threshold = 0.8
ensemble_size = 3

[mcp]
# Model Context Protocol servers
api_server = "http://localhost:8001"
tools_server = "http://localhost:8002"
data_server = "http://localhost:8003"
feedback_server = "http://localhost:8004"

# Caching configuration
cache_ttl_hours = 24
cache_path = ".cache/mcp/"
enable_offline_fallback = true

[agentic]
# Agentic system configuration
max_agents = 8
task_decomposition_threshold = 50  # lines of code
parallel_execution = true
ensemble_voting = true
error_rate_threshold = 0.01  # 1% max error rate

# Agent types
[agentic.agents]
code_agent = { enabled = true, specialization = "code_generation" }
math_agent = { enabled = true, specialization = "mathematical_reasoning" }
text_agent = { enabled = true, specialization = "natural_language" }
debug_agent = { enabled = true, specialization = "debugging" }

[performance]
# Performance monitoring
enable_energy_monitoring = true
enable_latency_tracking = true
enable_memory_tracking = true
enable_accuracy_tracking = true

# Thresholds and alerts
latency_alert_threshold_ms = 120
power_alert_threshold_w = 60.0
memory_alert_threshold_gb = 10.0
accuracy_alert_threshold = 0.95

[logging]
# Logging configuration
level = "info"
structured = false
file_path = "logs/"
enable_performance_logs = true
enable_training_logs = true

[security]
# Security settings
enable_input_sanitization = true
enable_output_validation = true
max_input_length = 10000
enable_rate_limiting = true
rate_limit_requests_per_minute = 60

[validation]
# Zero-hallucination validation
enable_type_checking = true
enable_syntax_validation = true
enable_cross_validation = true
enable_confidence_scoring = true
min_confidence_threshold = 0.9

[benchmarks]
# Benchmark configuration
humaneval_target_accuracy = 0.95
gsm8k_target_accuracy = 0.90
inference_speed_target_ms = 100
energy_efficiency_target_w = 50
training_time_target_hours = 24