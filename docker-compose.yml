# Docker Compose for Ultra-Fast AI Model Training Environment
# Supports RTX 2070 Ti simulation and multi-language development

version: '3.8'

services:
  # Main development environment with all tools
  dev-environment:
    build:
      context: .
      dockerfile: Dockerfile
      target: development
    container_name: ice-ai-dev
    volumes:
      - .:/workspace
      - cargo-cache:/usr/local/cargo/registry
      - zig-cache:/workspace/zig-cache
      - go-cache:/go/pkg/mod
      - ./target:/workspace/target
    working_dir: /workspace
    environment:
      - RUST_LOG=debug
      - CARGO_TARGET_DIR=/workspace/target
      - ZIG_CACHE_DIR=/workspace/zig-cache
      - GOCACHE=/go/pkg/mod
    ports:
      - "8080:8080"  # Development server
      - "3000:3000"  # Frontend (if needed)
      - "9090:9090"  # Metrics/monitoring
    command: tail -f /dev/null
    networks:
      - ai-network

  # Training environment (GPU simulation)
  training:
    build:
      context: .
      dockerfile: Dockerfile
      target: training
    container_name: ice-ai-training
    volumes:
      - .:/workspace
      - training-data:/workspace/datasets
      - model-checkpoints:/workspace/checkpoints
      - ./target:/workspace/target
    working_dir: /workspace
    environment:
      - RUST_LOG=info
      - CUDA_VISIBLE_DEVICES=0
      - TRAINING_MODE=gpu_simulation
      - MAX_TRAINING_HOURS=24
      - TARGET_PARAMS=100M
    deploy:
      resources:
        reservations:
          memory: 8G
        limits:
          memory: 16G
    networks:
      - ai-network
    profiles:
      - training

  # MCP server environment
  mcp-servers:
    build:
      context: .
      dockerfile: Dockerfile
      target: mcp
    container_name: ice-mcp-servers
    volumes:
      - .:/workspace
      - mcp-cache:/workspace/.cache/mcp
    working_dir: /workspace
    environment:
      - MCP_CACHE_TTL=86400  # 24 hours
      - MCP_SERVER_PORT=8001
      - GO_ENV=development
    ports:
      - "8001:8001"  # MCP API server
      - "8002:8002"  # MCP Tools server
      - "8003:8003"  # MCP Data server
      - "8004:8004"  # MCP Feedback server
    networks:
      - ai-network
    depends_on:
      - dev-environment

  # Testing environment
  test-runner:
    build:
      context: .
      dockerfile: Dockerfile
      target: testing
    container_name: ice-test-runner
    volumes:
      - .:/workspace
      - test-results:/workspace/test-results
      - ./target:/workspace/target
    working_dir: /workspace
    environment:
      - RUST_TEST_THREADS=4
      - TEST_COVERAGE_THRESHOLD=100
      - MUTATION_SCORE_THRESHOLD=80
    networks:
      - ai-network
    profiles:
      - testing

  # Performance monitoring
  monitoring:
    image: prom/prometheus:latest
    container_name: ice-monitoring
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
    networks:
      - ai-network
    profiles:
      - monitoring

  # Grafana for visualization
  grafana:
    image: grafana/grafana:latest
    container_name: ice-grafana
    ports:
      - "3001:3000"
    volumes:
      - grafana-data:/var/lib/grafana
      - ./monitoring/grafana/:/etc/grafana/provisioning/
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin123
      - GF_USERS_ALLOW_SIGN_UP=false
    networks:
      - ai-network
    profiles:
      - monitoring
    depends_on:
      - monitoring

networks:
  ai-network:
    driver: bridge

volumes:
  cargo-cache:
    driver: local
  zig-cache:
    driver: local
  go-cache:
    driver: local
  training-data:
    driver: local
  model-checkpoints:
    driver: local
  mcp-cache:
    driver: local
  test-results:
    driver: local
  prometheus-data:
    driver: local
  grafana-data:
    driver: local

# Usage:
#   docker-compose up dev-environment mcp-servers
#   docker-compose --profile training up
#   docker-compose --profile testing up
#   docker-compose --profile monitoring up
