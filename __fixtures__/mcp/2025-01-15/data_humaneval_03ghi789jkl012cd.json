{
  "id": "data_humaneval_03ghi789jkl012cd",
  "operation_type": "data",
  "target": "humaneval_dataset",
  "request": {
    "dataset": "humaneval",
    "action": "fetch",
    "parameters": {
      "problem_ids": ["HumanEval/0", "HumanEval/1"],
      "include_tests": true,
      "format": "json"
    }
  },
  "response": {
    "problems": [
      {
        "task_id": "HumanEval/0",
        "prompt": "def has_close_elements(numbers, threshold):\n    \"\"\" Check if any two numbers are closer than threshold.\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\n    False\n    \"\"\"\n",
        "canonical_solution": "    for i, elem in enumerate(numbers):\n        for j, elem2 in enumerate(numbers):\n            if i != j and abs(elem - elem2) < threshold:\n                return True\n    return False\n",
        "test": "assert has_close_elements([1.0, 2.0, 3.9, 4.0, 5.0, 2.2], 0.3) == True",
        "entry_point": "has_close_elements"
      },
      {
        "task_id": "HumanEval/1", 
        "prompt": "def separate_paren_groups(paren_string):\n    \"\"\" Separate groups of balanced parentheses.\n    >>> separate_paren_groups('( ) (( )) (( )( ))')\n    ['()', '(())', '(()())']\n    \"\"\"\n",
        "canonical_solution": "    result = []\n    current_string = []\n    current_depth = 0\n    for c in paren_string:\n        if c == '(':\n            current_depth += 1\n            current_string.append(c)\n        elif c == ')':\n            current_depth -= 1\n            current_string.append(c)\n            if current_depth == 0:\n                result.append(''.join(current_string))\n                current_string = []\n    return result\n",
        "test": "assert separate_paren_groups('( ) (( )) (( )( ))') == ['()', '(())', '(()())']",
        "entry_point": "separate_paren_groups"
      }
    ],
    "total_problems": 2,
    "fetch_time_ms": 150
  },
  "metadata": {
    "created_at": "2025-01-15T14:22:45Z",
    "created_by": "ultra-fast-ai",
    "description": "HumanEval dataset fetch for code generation benchmarking",
    "expected_response_time_ms": 200,
    "status_code": null,
    "is_error": false,
    "version": "1.0"
  },
  "tags": ["dataset", "humaneval", "benchmark", "code-generation", "data-access"]
}